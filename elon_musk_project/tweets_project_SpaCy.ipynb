{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "from spacy.lang.en import English\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "# from spacy.gold import GoldParse\n",
    "from spacy.pipeline import EntityRecognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get path for all tweet files to concatenate them\n",
    "path = r'./elon_musk_tweets'\n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "\n",
    "li = []\n",
    "\n",
    "for filename in all_files:\n",
    "    # print(filename)\n",
    "    frame = pd.read_csv(filename, index_col=None, encoding=\"utf-8\")\n",
    "    li.append(frame)\n",
    "\n",
    "# print(li)\n",
    "df = pd.concat(li, axis=0, ignore_index=True)\n",
    "df.shape\n",
    "# df[35000:35101]\n",
    "# df.head(30)\n",
    "# df.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_elon = df[[\"date\",\"tweet\"]]\n",
    "# df = df.drop(['id','conversation_id','created_at','timezone','place','language','near','geo','source','user_rt_id','user_rt', 'retweet_id','reply_to','translate','trans_dest','cashtags','user_id', 'user_id_str','day','video','thumbnail','quote_url','search','trans_src','link','urls', 'photos'], 1)\n",
    "# df.date[30550]\n",
    "# df[:10]\n",
    "df_elon.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving tweets to a list\n",
    "dates = df[\"date\"].to_list()\n",
    "print(dates[-1])\n",
    "tweets = df[\"tweet\"].to_list()\n",
    "len(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # function to find entities with spacy and see their labels and explanation\n",
    "# def show_ents(doc):\n",
    "#     doc = nlp(doc)\n",
    "#     if doc.ents:\n",
    "#         for ent in doc.ents:\n",
    "#             print(ent.text+\" - \"+str(ent.start_char) +\" - \"+ str(ent.end_char) +\" - \"+ent.label_+ \" - \"+str(spacy.explain(ent.label_)))\n",
    "#     else:\n",
    "#         print(\"No named entities found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # function check\n",
    "# show_ents(tweets[253])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to collect a dictionary with ORG entities mentioned, tweets and dates\n",
    "\n",
    "def mentioned_orgs(tweets):\n",
    "    \"\"\"Function takes in a list of tweets and returns a dictionary with organisation's name as a key and a list of tweets and dates of posting as a value\"\"\"\n",
    "    elon_companies = {}\n",
    "    count = 0\n",
    "    for doc in tweets:\n",
    "        doc = nlp(doc) # text processing\n",
    "        if doc.ents:\n",
    "        # searching for named entities that stand for ORG\n",
    "            for ent in doc.ents:\n",
    "                if ent.label_==\"ORG\":\n",
    "                # print(ent, type(ent))\n",
    "                    ent = str(ent)\n",
    "                    if ent in elon_companies:\n",
    "                        elon_companies[ent].append(list())\n",
    "                        elon_companies[ent][-1].append(dates[count])\n",
    "                        elon_companies[ent][-1].append(tweets[count]) #adding dates to the value\n",
    "                    else:\n",
    "                        elon_companies[ent] = list()\n",
    "                        elon_companies[ent].append(list())\n",
    "                        elon_companies[ent][0].append(dates[count])\n",
    "                        elon_companies[ent][0].append(tweets[count])\n",
    "        count += 1\n",
    "\n",
    "    return elon_companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies = mentioned_orgs(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dctionary to count times each company was mentioned\n",
    "elon_top_companies = {}\n",
    "for k in companies:\n",
    "    elon_top_companies[k] = len(companies[k])\n",
    "    # print(k, len(elon_companies[k]))\n",
    "    \n",
    "print(elon_top_companies)\n",
    "# print(len(elon_companies[\"Tesla\"]), elon_companies[\"Tesla\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorting dictionary in descending order\n",
    "elon_top_companies = sorted(elon_top_companies.items(), key=lambda x: x[1], reverse=True)\n",
    "print(\"Companies Elon Musk most talks about:\\n\")\n",
    "count = 1\n",
    "for k,v in elon_top_companies[:21]:\n",
    "    print(\"{}. {} ({} tweets)\".format(count, k, v))\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comp_products = {\n",
    "    # \"Model S\": \"Tesla\"\n",
    "# }\n",
    "\n",
    "comp_products = {\n",
    "    \"Zip2\": \"Zip2\",\n",
    "    \"Falcon\": \"SpaceX\",\n",
    "    \"Falcon Heavy\": \"SpaceX\",\n",
    "    \"Falcon 9\": \"SpaceX\",\n",
    "    \"Grasshopper\": \"SpaceX\", \n",
    "    \"Starship\": \"SpaceX\", \n",
    "    \"Merlin\": \"SpaceX\", \n",
    "    \"Kestrel\": \"SpaceX\", \n",
    "    \"Raptor\": \"SpaceX\", \n",
    "    \"Methox thruster\": \"SpaceX\", \n",
    "    \"Draco\": \"SpaceX\", \n",
    "    \"SuperDraco\": \"SpaceX\", \n",
    "    \"Dragon\": \"SpaceX\", \n",
    "    \"Cargo Dragon\": \"SpaceX\", \n",
    "    \"Starlink\": \"SpaceX\", \n",
    "    \"Hyperloop\": \"SpaceX\", \n",
    "    \"vactrain\": \"SpaceX\",\n",
    "    \"Model S\": \"Tesla\",\n",
    "    \"Roadster\": \"Tesla\",\n",
    "    \"Model X\": \"Tesla\", \n",
    "    \"Model 3\": \"Tesla\", \n",
    "    \"Model Y\": \"Tesla\", \n",
    "    \"Semi\": \"Tesla\", \n",
    "    \"Cybertruck\": \"Tesla\", \n",
    "    \"Powerwall\": \"Tesla\", \n",
    "    \"Solar Roof\": \"Tesla\", \n",
    "    \"Solar Inverter\": \"Tesla\", \n",
    "    \"Powerpack\": \"Tesla\", \n",
    "    \"Megapack\": \"Tesla\", \n",
    "    \"Supercharger\": \"Tesla\", \n",
    "    \"Destination charger\": \"Tesla\", \n",
    "    \"Autopilot\": \"Tesla\", \n",
    "    \"Full self-driving\": \"Tesla\", \n",
    "    \"FSD\": \"Tesla\",\n",
    "    \"Application-Specific Integrated Circuit\": \"Neuralink\",\n",
    "    \"ASIC\": \"Neuralink\", \n",
    "    \"brain-computer interface\": \"Neuralink\",\n",
    "    \"Hawthorne tunnel\": \"The Boring Company\", \n",
    "    \"Los Angeles tunnel\": \"The Boring Company\", \n",
    "    \"Loop\": \"The Boring Company\", \n",
    "    \"Loop System\": \"The Boring Company\",\n",
    "    \"Gym\": \"OpenAI\", \n",
    "    \"RoboSumo\": \"OpenAI\", \n",
    "    \"Debate Game\": \"OpenAI\", \n",
    "    \"Dactyl\": \"OpenAI\", \n",
    "    \"GPT\": \"OpenAI\", \n",
    "    \"generative pre-training\": \"OpenAI\", \n",
    "    \"GPT-2\": \"OpenAI\", \n",
    "    \"GPT-3\": \"OpenAI\", \n",
    "    \"MuseNet\": \"OpenAI\", \n",
    "    \"API\": \"OpenAI\", \n",
    "    \"DALL-E\": \"OpenAI\", \n",
    "    \"CLIP\": \"OpenAI\", \n",
    "    \"Microscope\": \"OpenAI\", \n",
    "    \"Codex\": \"OpenAI\", \n",
    "    \"Five\": \"OpenAI\", \n",
    "    \"GYM Retro\": \"OpenAI\"\n",
    "}\n",
    "\n",
    "# print(comp_products[\"Model S\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning data processed with Spacy checking the entities against the names of companies' products.\n",
    "new_d = {}\n",
    "for k in companies:\n",
    "    if k in comp_products:\n",
    "        # print(k)\n",
    "        # print(comp_products[k])\n",
    "        # print(companies[k])\n",
    "        if comp_products[k] not in new_d:\n",
    "            new_d[comp_products[k]] = companies[k]\n",
    "        else:\n",
    "            new_d[comp_products[k]].extend(companies[k])\n",
    "    else:\n",
    "        if k in new_d:\n",
    "            # print(k)\n",
    "            new_d[k].extend(companies[k])\n",
    "        else:\n",
    "            # print(k)\n",
    "            new_d[k] = companies[k]\n",
    "\n",
    "# print(len(new_d[\"Tesla\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary to count times each company was mentioned\n",
    "new_d_count = {}\n",
    "for k in new_d:\n",
    "    new_d_count[k] = len(new_d[k])\n",
    "    # print(k, len(elon_companies[k]))\n",
    "    \n",
    "# print(new_d_count)\n",
    "\n",
    "new_d_sorted = sorted(new_d_count.items(), key=lambda x: x[1], reverse=True)\n",
    "print(\"Companies Elon Musk most talks about:\\n\")\n",
    "count = 1\n",
    "for k,v in new_d_sorted[:31]:\n",
    "    print(\"{}. {} ({} tweets)\".format(count, k, v))\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count = 0\n",
    "# for k in companies:\n",
    "#     for c in comp_products:\n",
    "#         for item in comp_products[c]:\n",
    "#             if k == item:\n",
    "#                 count += 1\n",
    "#                 print(k, \"vs.\", item, \"\\n\")\n",
    "# print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def company_tweets_to_list(companies_dict, company_name):\n",
    "    \"\"\"Function takes in a dictionary with tweets about companies and a string with the name of a company under consideration\"\"\"\n",
    "    comp_tweets = []\n",
    "\n",
    "    idx = 0\n",
    "    while idx in range(len(companies_dict[company_name])):\n",
    "        comp_tweets.append(companies_dict[company_name][idx][1])\n",
    "        idx += 1\n",
    "\n",
    "    return comp_tweets\n",
    "    # for key in new_d:\n",
    "    #     idx = 0\n",
    "    #     while idx in range(len(new_d[key])):\n",
    "    #         comp_tweets.append(new_d[key][idx][1])\n",
    "    #         idx += 1\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tesla_tweets = company_tweets_to_list(new_d, company_name=\"Tesla\")\n",
    "# tesla_tweets[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacex_tweets = company_tweets_to_list(new_d, company_name=\"SpaceX\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "nasa_tweets = company_tweets_to_list(new_d, company_name=\"@NASA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbc_tweets = company_tweets_to_list(new_d, company_name=\"The Boring Company\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_tweets = company_tweets_to_list(new_d, company_name=\"Google\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple_tweets = company_tweets_to_list(new_d, company_name=\"Apple\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_analyzer(lst_texts):\n",
    "    \"\"\"Function takes in a list of texts and returns a dictionary with keys as numbers and text and sentiment scores with explanation for a value\"\"\"\n",
    "    data = {}\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    count = 0\n",
    "    for text in lst_texts:\n",
    "        vs = analyzer.polarity_scores(text)\n",
    "        data[count] = list()\n",
    "        data[count].extend([text, vs])\n",
    "        data[count].append(data[count][1]['compound'])\n",
    "        if data[count][1]['compound'] > 0:\n",
    "            data[count].append(\"POSITIVE\")\n",
    "        elif data[count][1]['compound'] == 0:\n",
    "            data[count].append(\"NEUTRAL\")\n",
    "        else:\n",
    "            data[count].append(\"NEGATIVE\")\n",
    "        count += 1\n",
    "    # print(data[3000])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "tesla = sentiment_analyzer(tesla_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tesla_df = pd.DataFrame.from_dict(tesla, orient=\"index\",columns=[\"Tweet\",\"Scores\", \"Compound\", \"Sentiment_type\"])\n",
    "tesla_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tesla_df.Sentiment_type.value_counts().plot(kind=\"bar\", title=\"Tesla Sentiment Analysis\", color=\"#55FF33\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacex = sentiment_analyzer(spacex_tweets)\n",
    "spacex_df = pd.DataFrame.from_dict(spacex, orient=\"index\",columns=[\"Tweet\",\"Scores\", \"Compound\", \"Sentiment_type\"])\n",
    "spacex_df\n",
    "spacex_df.Sentiment_type.value_counts().plot(kind='bar',title=\"SpaceX sentiment analysis\", color=\"#3396FF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nasa = sentiment_analyzer(nasa_tweets)\n",
    "nasa_df = pd.DataFrame.from_dict(nasa, orient=\"index\",columns=[\"Tweet\",\"Scores\", \"Compound\", \"Sentiment_type\"])\n",
    "nasa_df\n",
    "nasa_df.Sentiment_type.value_counts().plot(kind='bar',title=\"NASA Sentiment Analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbc = sentiment_analyzer(tbc_tweets)\n",
    "tbc_df = pd.DataFrame.from_dict(tbc, orient=\"index\",columns=[\"Tweet\",\"Scores\", \"Compound\", \"Sentiment_type\"])\n",
    "tbc_df\n",
    "tbc_df.Sentiment_type.value_counts().plot(kind='bar',title=\"The Boring Company Sentiment Analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "google = sentiment_analyzer(google_tweets)\n",
    "google_df = pd.DataFrame.from_dict(google, orient=\"index\",columns=[\"Tweet\",\"Scores\", \"Compound\", \"Sentiment_type\"])\n",
    "google_df\n",
    "google_df.Sentiment_type.value_counts().plot(kind='bar',title=\"Google Sentiment Analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple = sentiment_analyzer(apple_tweets)\n",
    "apple_df = pd.DataFrame.from_dict(apple, orient=\"index\",columns=[\"Tweet\",\"Scores\", \"Compound\", \"Sentiment_type\"])\n",
    "apple_df\n",
    "apple_df.Sentiment_type.value_counts().plot(kind='bar',title=\"Apple Sentiment Analysis\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0adcc2737ebf6a4a119f135174df96668767fca1ef1112612db5ecadf2b6d608"
  },
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
